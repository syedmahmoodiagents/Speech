{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAGHSysRU5Wac5TGuBzztH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedmahmoodiagents/Speech/blob/main/SimpleWaveNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf"
      ],
      "metadata": {
        "id": "9CWjTTSWobkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_small = torch.tensor([1e-15, 0.0, 1.0])\n",
        "\n",
        "\n",
        "y_loge = torch.log(x_small)\n",
        "print(f\"log_e result: {y_loge}\")\n",
        "\n",
        "y_log_direct = torch.log(1 + x_small)\n",
        "print(f\"log(1 + x) result: {y_log_direct}\")\n",
        "\n",
        "y_log1p = torch.log1p(x_small)\n",
        "print(f\"log1p result: {y_log1p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7NrShtVGXDv",
        "outputId": "4627ee04-c960-4977-9dda-7f432be39add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_e result: tensor([-34.5388,     -inf,   0.0000])\n",
            "log(1 + x) result: tensor([0.0000, 0.0000, 0.6931])\n",
            "log1p result: tensor([1.0000e-15, 0.0000e+00, 6.9315e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sign(torch.tensor([-2.3, 1.8, -0.001, 0.7, -0.8, 9.8]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g24PKRaxHgax",
        "outputId": "2a33feac-19f4-4f9a-a21e-af627106fc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.,  1., -1.,  1., -1.,  1.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqjCsrByoXyf"
      },
      "outputs": [],
      "source": [
        "def mu_law_encode(x, mu=256):\n",
        "    x = torch.clamp(x, -1.0, 1.0) # Clamp input to [-1, 1] range\n",
        "    # mu_val_for_formula = mu - 1\n",
        "    # Ensure the scalar 'mu' is a tensor of the same dtype as 'x' for log1p\n",
        "    mu_tensor = torch.tensor(mu - 1, dtype=x.dtype)\n",
        "    return torch.sign(x) * torch.log1p((mu - 1) * torch.abs(x)) / torch.log1p(mu_tensor)\n",
        "\n",
        "def quantize(x, mu=256):\n",
        "    x = mu_law_encode(x, mu)\n",
        "    return ((x + 1) / 2 * (mu - 1)).long()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CausalConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
        "        super().__init__()\n",
        "        self.padding = (kernel_size - 1) * dilation\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels, out_channels,\n",
        "            kernel_size,\n",
        "            padding=self.padding,\n",
        "            dilation=dilation\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        return out[:, :, :-self.padding]  # remove future leakage\n"
      ],
      "metadata": {
        "id": "GAqJISG-oeZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WaveNetBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_size, dilation):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = CausalConv1d(\n",
        "            channels, 2 * channels, kernel_size, dilation\n",
        "        )\n",
        "\n",
        "        self.residual = nn.Conv1d(channels, channels, kernel_size=1)\n",
        "        self.skip = nn.Conv1d(channels, channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "\n",
        "        tanh, sigmoid = out.chunk(2, dim=1)\n",
        "        gated = torch.tanh(tanh) * torch.sigmoid(sigmoid)\n",
        "\n",
        "        residual = self.residual(gated)\n",
        "        skip = self.skip(gated)\n",
        "\n",
        "        return x + residual, skip\n"
      ],
      "metadata": {
        "id": "hrXQL9-3ocOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WaveNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, channels=64, kernel_size=2, num_blocks=3, layers_per_block=10, num_classes=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_conv = nn.Conv1d(in_channels, channels, kernel_size=1)\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        dilations = []\n",
        "\n",
        "        for _ in range(num_blocks):\n",
        "            for i in range(layers_per_block):\n",
        "                dilation = 2 ** i\n",
        "                self.blocks.append(\n",
        "                    WaveNetBlock(channels, kernel_size, dilation)\n",
        "                )\n",
        "                dilations.append(dilation)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output_conv = nn.Sequential(\n",
        "            nn.Conv1d(channels, channels, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_conv(x)\n",
        "\n",
        "        skip_connections = []\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x, skip = block(x)\n",
        "            skip_connections.append(skip)\n",
        "\n",
        "        out = sum(skip_connections)\n",
        "        out = self.relu(out)\n",
        "        out = self.output_conv(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "SKPa0-mDsokQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3195973"
      },
      "source": [
        "\n",
        "dummy_audio_path = 'dummy_audio.wav'\n",
        "sr = 16000\n",
        "duration = 5 # seconds\n",
        "y_dummy = np.random.uniform(low=-1.0, high=1.0, size=sr*duration).astype(np.float32)\n",
        "sf.write(dummy_audio_path, y_dummy, sr)\n",
        "\n",
        "y, sr = librosa.load(dummy_audio_path, sr=16000) # Load at a specific sample rate, e.g., 16 kHz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "audio_input_tensor = torch.from_numpy(y).float()\n",
        "audio_input_tensor = audio_input_tensor.unsqueeze(0).unsqueeze(0) # [Batch=1, channel=1 (mono), length of vector]"
      ],
      "metadata": {
        "id": "Br2pkSlX6o2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clipped_audio_input_tensor = audio_input_tensor[:, :, :16000]\n",
        "\n",
        "print(f\"Clipped audio input tensor shape: {clipped_audio_input_tensor.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTrVvoEX7cZj",
        "outputId": "6b9f176d-f821-4e99-e1a2-cdf3b4e981e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clipped audio input tensor shape: torch.Size([1, 1, 16000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = WaveNet()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ZMTM2caRCn37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = clipped_audio_input_tensor\n",
        "y = quantize(x[:, :, 1:])      # next sample\n",
        "x = x[:, :, :-1]"
      ],
      "metadata": {
        "id": "QVsEj3t3srf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(x)\n",
        "loss = criterion(logits, y.squeeze(1))\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QySIwIj8ek-",
        "outputId": "bacc6169-c7fb-45a7-df67-f6e5ac794dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.5642, grad_fn=<NllLoss2DBackward0>)\n"
          ]
        }
      ]
    }
  ]
}